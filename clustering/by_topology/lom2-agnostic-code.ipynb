{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx  # pip install --user networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_pickle(\"cachenodes.pkl\")\n",
    "edges = pd.read_pickle(\"edges.pkl\")\n",
    "comp_nodes = pd.read_pickle(\"comp_nodes.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topology(nodes, edges):\n",
    "    topology = nx.Graph()\n",
    "    \n",
    "    # add all nodes\n",
    "    for index, row in nodes.iterrows():\n",
    "        node_name = row[\"name\"]\n",
    "        node_attributes = row.drop([\"name\"]).to_dict()\n",
    "        topology.add_node(node_name, **node_attributes)\n",
    "    \n",
    "    # add all edges\n",
    "    for index, row in edges.iterrows():\n",
    "        node1_name = row[\"node1\"]\n",
    "        node2_name = row[\"node2\"]\n",
    "        edge_attributes = row.drop([\"node1\", \"node2\"]).to_dict()\n",
    "        topology.add_edge(node1_name, node2_name, **edge_attributes)\n",
    "    \n",
    "    return topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology = build_topology(nodes, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate shortest path for every pair of computational nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function for caching of results\n",
    "\n",
    "It allows the program to save calculated tables or other objects\n",
    "or load them from disk if they are already there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libcrap.core import calcsave_or_load\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_diskcache = partial(calcsave_or_load, load_func=pd.read_pickle, save_func=pd.to_pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually do the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd_diskcache(\"paths.pkl\")\n",
    "def find_comp_to_comp_shortest_paths(topology, comp_nodes):\n",
    "    paths_ugly = dict(nx.all_pairs_shortest_path(topology))\n",
    "    # calculates shortest paths and stores them in a dict of dicts\n",
    "    \n",
    "    # build a table with all computational node pairs\n",
    "    # they are not duplicated\n",
    "    # if there is (\"n48001\", \"n49419\") then there is no (\"n49419\", \"n48001\") pair\n",
    "    comp_node_pairs = pd.DataFrame.from_records(\n",
    "        itertools.chain.from_iterable(\n",
    "            [(node1, node2) for node2 in comp_nodes.iloc[index:]]\n",
    "            for (index, node1) in comp_nodes.iteritems()\n",
    "        ),\n",
    "        columns=[\"node1\", \"node2\"]\n",
    "    )\n",
    "\n",
    "    # write shortest paths to this table\n",
    "    comp_node_pairs[\"shortest_path\"] = comp_node_pairs.apply(\n",
    "        lambda row: paths_ugly[row.loc[\"node1\"]][row.loc[\"node2\"]],\n",
    "        axis=1\n",
    "    )\n",
    "    return comp_node_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shortest paths between all computational nodes\n",
    "paths = find_comp_to_comp_shortest_paths(topology, comp_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate feature lists of these paths\n",
    "\n",
    "We also add a new column to **paths** table here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interleave(it1, it2):\n",
    "    \"\"\"\n",
    "    >>> list(interleave([1, 2, 3, 4], [\"a\", \"b\", \"c\"]))\n",
    "    [1, 'a', 2, 'b', 3, 'c', 4]\n",
    "    \"\"\"\n",
    "    return (\n",
    "        item for item\n",
    "        in itertools.chain.from_iterable(itertools.zip_longest(it1, it2))\n",
    "        if item is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_features(topology, node):\n",
    "    \"\"\"Returns node features as a tuple of tuples.\n",
    "    \n",
    "    >>> topology = nx.Graph()\n",
    "    >>> topology.add_node(\"kek\", a=1, b=\"lol\")\n",
    "    >>> sorted(get_node_features(topology, \"kek\"), key=lambda pair: pair[0])\n",
    "    [('a', 1), ('b', 'lol')]\n",
    "    \"\"\"\n",
    "    return tuple(topology.node[node].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_features(topology, node1, node2):\n",
    "    \"\"\"Returns features of an edge as tuple of tuples.\n",
    "    \n",
    "    >>> topology = nx.Graph()\n",
    "    >>> topology.add_node(\"a1\")\n",
    "    >>> topology.add_node(\"b1\")\n",
    "    >>> topology.add_edge(\"a1\", \"b1\", foo=\"bar\", shim=\"sham\")\n",
    "    >>> get_edge_features(topology, \"a1\", \"b1\")\n",
    "    (('foo', 'bar'), ('shim', 'sham'))\n",
    "    \"\"\"\n",
    "    return tuple(topology.edges[node1, node2].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_reverse(l):\n",
    "    \"\"\"\n",
    "    Takes list or tuple and reverses it, or not.\n",
    "    Using maybe_reverse on some list and on its reversed version will\n",
    "    yield the same result.\n",
    "    \n",
    "    >>> maybe_reverse([1, 2, 3])\n",
    "    [1, 2, 3]\n",
    "    >>> maybe_reverse([3, 2, 1])\n",
    "    [1, 2, 3]\n",
    "    >>> maybe_reverse(('a', 'b', 'c'))\n",
    "    ('a', 'b', 'c')\n",
    "    >>> maybe_reverse(('c', 'b', 'a'))\n",
    "    ('a', 'b', 'c')\n",
    "    \"\"\"\n",
    "    if type(l) == list:\n",
    "        constructor = list\n",
    "    elif type(l) == tuple:\n",
    "        constructor = tuple\n",
    "    else:\n",
    "        raise TypeError(\"can only take list or tuple arguments\")\n",
    "        \n",
    "    reversed_l = constructor(reversed(l))\n",
    "    if str(l) <= str(reversed_l):\n",
    "        return l\n",
    "    return reversed_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_of_path(topology, path):\n",
    "    \"\"\"Returns features of path as a tuple of tuples of tuples.\n",
    "    The list of features will be normalized, so that\n",
    "    this function returns the same features in the same order for\n",
    "    path (A, B, C, D) and for path (D, C, B, A)\"\"\"\n",
    "    nodes_features = (get_node_features(topology, node) for node in path)\n",
    "    \n",
    "    edges_features = (get_edge_features(topology, node1, node2)\n",
    "                        for (node1, node2) in zip(path[:-1], path[1:]))\n",
    "    return maybe_reverse(tuple(interleave(nodes_features, edges_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_loc_by_sequence(df, sequence):\n",
    "    \"\"\"\n",
    "    Use this instead of `df.loc[sequence]`.\n",
    "    \n",
    "    Pandas df gets confused by tuples and possibly by other\n",
    "    sequences. If you do `df.loc[(1, 2)]`, it will look for 1\n",
    "    or 2 in df's index instead of looking for the tuple itself.\n",
    "    You can use df.xs to overcome this problem. Or use this\n",
    "    function which hides the ugliness.\n",
    "    \n",
    "    Also see\n",
    "    [stackoverflow question](https://goo.gl/emtjB8)\n",
    "    for better description of the problem.\"\"\"\n",
    "    \n",
    "    return df.xs(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_node_features():\n",
    "    doctest.run_docstring_examples(get_node_features, globals())\n",
    "    assert get_node_features(topology, \"КГК.48.0.3\") == ((\"type_\", \"switch\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_get_edge_features():\n",
    "    doctest.run_docstring_examples(get_edge_features, globals())\n",
    "    \n",
    "    correct_result = ((\"connection_type\", \"backplane\"),)\n",
    "    result1 = get_edge_features(topology, \"КГК.48.0.3\", \"n48022\")\n",
    "    result2 = get_edge_features(topology, \"n48022\", \"КГК.48.0.3\")\n",
    "    assert result1 == correct_result == result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doctest.run_docstring_examples(interleave, globals())\n",
    "test_get_node_features()\n",
    "test_get_edge_features()\n",
    "doctest.run_docstring_examples(maybe_reverse, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd_diskcache(\"classes.pkl\")\n",
    "def list_path_classes(topology, paths):\n",
    "    unique_features_classes = frozenset(\n",
    "        get_features_of_path(topology, path)\n",
    "        for path in paths[\"shortest_path\"]\n",
    "    )\n",
    "    \n",
    "    return pd.DataFrame.from_records(\n",
    "        ([features] for features in sorted(unique_features_classes)),\n",
    "        columns=[\"features\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pd_diskcache(\"paths_with_classes.pkl\")\n",
    "def add_class_id_col(paths, classes):\n",
    "    \"\"\"Adds class_id column to paths table\"\"\"\n",
    "    \n",
    "    # create pandas table for quick getting index by value of features list\n",
    "    classes_reverse_lookup = classes.reset_index().set_index(\"features\", verify_integrity=True)\n",
    "    \n",
    "    def get_class_id_by_path(path):\n",
    "        return df_loc_by_sequence(classes_reverse_lookup, get_features_of_path(topology, path))[\"index\"]\n",
    "    \n",
    "    return paths.assign(class_=paths[\"shortest_path\"].apply(get_class_id_by_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list_path_classes(topology, paths)\n",
    "paths_with_classes = add_class_id_col(paths, classes)"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
